# MCP
## MCP Server Vulnerabilities
| affected mcp server | vuln | link |
| ------------------- | ---- | ---- |
| aws-mcp-server | command injection | https://x.com/UjlakiMarci/status/1927825607137640950 |
| github-mcp-server | command injection | https://invariantlabs.ai/blog/mcp-github-vulnerability |

https://embracethered.com/blog/posts/2025/model-context-protocol-security-risks-and-exploits/ \
https://www.cyberark.com/resources/threat-research-blog/poison-everywhere-no-output-from-your-mcp-server-is-safe \

https://github.com/stacklok/toolhive \
https://github.com/microsandbox/microsandbox \
https://github.com/tuananh/hyper-mcp \
https://hack.mcpwned.com/dashboard/scanner

### MCP PAM
https://www.querypie.com/ 

## Reading
https://www.nccgroup.com/us/research-blog/5-mcp-security-tips/

## Toxic agent flows

# Secure GenAI (Vibe)Coding
## Rules Files / System Prompts / Custom Instructions
https://github.com/untamed-theory/vibesec \
https://github.com/wiz-sec-public/secure-rules-files

# General
## Frameworks
https://atlas.mitre.org/matrices/ATLAS \
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf 

## General Security / Risk Benchmarks
https://phare.giskard.ai/ \
https://realharm.giskard.ai/

# Architecture
https://www.nccgroup.com/us/research-blog/analyzing-secure-ai-architectures/ \
https://techcommunity.microsoft.com/blog/microsoft-security-blog/best-practices-to-architect-secure-generative-ai-applications/4116661 \
https://www.nccgroup.com/us/research-blog/analyzing-secure-ai-design-principles/ \
https://www.nccgroup.com/us/research-blog/where-you-inject-matters-the-role-specific-impact-of-prompt-injection-attacks-on-openai-models/ \
https://www.nccgroup.com/us/research-blog/analyzing-ai-application-threat-models/

# Lists
https://github.com/corca-ai/awesome-llm-security \
https://github.com/ydyjya/Awesome-LLM-Safety \
https://github.com/christiancscott/awesome-LLM-security \
https://github.com/ShenaoW/awesome-llm-supply-chain-security \
https://github.com/wearetyomsmnv/Awesome-LLMSecOps \
https://github.com/wearetyomsmnv/Awesome-LLM-agent-Security \
https://github.com/ThuCCSLab/Awesome-LM-SSP \
https://github.com/asgeirtj/system_prompts_leaks


## Attacks / Countermeasures / Research
https://arxiv.org/html/2505.08807v1 - Security of Internet of Agents: Attacks and Countermeasures
https://arxiv.org/html/2505.00047v1 - Base Models Beat Aligned Models at Randomness and Creativity

# Prompt Injection
## General
https://github.com/Arcanum-Sec/arc_pi_taxonomy \
https://github.com/elder-plinius/L1B3RT4S \

# RT Guides / Tools
https://genai.owasp.org/resource/genai-red-teaming-guide/ \
https://elder-plinius.github.io/P4RS3LT0NGV3/

## Prompt Injection Benchmarks
https://github.com/lakeraai/pint-benchmark - lakera is the best! X*D \
https://gentellab.github.io/gentel-safe.github.io/ \
https://hiddenlayer.com/innovation-hub/evaluating-prompt-injection-datasets/ \
https://github.com/microsoft/BIPIA 

## Prompt Injection Benchmarking Datasets
https://huggingface.co/datasets/qualifire/Qualifire-prompt-injection-benchmark \
https://huggingface.co/datasets/xxz224/prompt-injection-attack-dataset \
https://huggingface.co/datasets/yanismiraoui/prompt_injections \
https://huggingface.co/datasets/jayavibhav/prompt-injection-safety \
https://huggingface.co/datasets/jayavibhav/prompt-injection \
https://huggingface.co/datasets/deepset/prompt-injections \
https://huggingface.co/datasets/hackaprompt/hackaprompt-dataset 

## Prompt Injection Benchmarking Research
https://arxiv.org/pdf/2403.02691 - INJECAGENT: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents \
https://arxiv.org/html/2505.00843 - OET: Optimization-based prompt injection Evaluation Toolkit \
https://arxiv.org/pdf/2312.14197 - Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models

## Prompt Injection Architecture Considerations
https://arxiv.org/pdf/2503.18813 - Defeating Prompt Injections by Design \
https://arxiv.org/pdf/2404.13208 - The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions \

## Prompt Injection Prevention Technologies / Realtime Protection 
Llama Guard: https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/ \
https://github.com/Defend-AI-Tech-Inc/wozway \
https://github.com/openshieldai/openshield \
https://github.com/eunomatix/llminspect-gateway \
https://www.lasso.security/ \
https://www.lakera.ai/ \
https://www.prompt.security/ \
https://www.troj.ai/ \
https://trust3.ai/ \
https://github.com/privacera/paig \
https://github.com/openlit/openlit

# SAST
https://reports.ghostsecurity.com/cast.pdf \
https://ghostsecurity.com/ \
https://www.dryrun.security/ \

# Developer Stuff
## Secrets
https://ampcode.com/news/secret-redaction

# LLM Scope Violation / Confused Agent/Deputy
https://www.aim.security/lp/aim-labs-echoleak-blogpost
